{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Load Necessary Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "seed = 5"
      ],
      "metadata": {
        "id": "l1_lwXeJNz3e"
      },
      "id": "l1_lwXeJNz3e",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare Saved Data"
      ],
      "metadata": {
        "id": "HjSp-MeaQ9Cn"
      },
      "id": "HjSp-MeaQ9Cn"
    },
    {
      "cell_type": "code",
      "source": [
        "## Load preprocessed file\n",
        "\n",
        "Xy_train = pd.read_csv('season_train.csv', sep = ',')\n",
        "Xy_test = pd.read_csv('season_test.csv', sep = ',')"
      ],
      "metadata": {
        "id": "nrGj6dySN0Ba"
      },
      "id": "nrGj6dySN0Ba",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(Xy_train.drop(columns = 'season').columns)"
      ],
      "metadata": {
        "id": "vGYNEE5yQgTo"
      },
      "id": "vGYNEE5yQgTo",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating outcome and explanatory variables into their resp. datasets\n",
        "\n",
        "X_train = pd.DataFrame(Xy_train[features])\n",
        "y_train = pd.DataFrame(Xy_train['season'])\n",
        "X_test = pd.DataFrame(Xy_test[features])\n",
        "y_test = pd.DataFrame(Xy_test['season'])"
      ],
      "metadata": {
        "id": "XUwCl3rrN5dI"
      },
      "id": "XUwCl3rrN5dI",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1trTRuN5fx",
        "outputId": "01b96f02-8e53-4d6f-ffd7-38f9c802ee04"
      },
      "id": "he1trTRuN5fx",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29923, 15) (29923, 1)\n",
            "(12825, 15) (12825, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the outcome variable since our model algorithms expects it as 1-d array\n",
        "\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcD3ilM6Qt9R",
        "outputId": "e1784664-a2b1-4e78-e50d-9220de73ae19"
      },
      "id": "dcD3ilM6Qt9R",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29923,), (12825,))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric"
      ],
      "metadata": {
        "id": "AA94I3ytjcrh"
      },
      "id": "AA94I3ytjcrh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use accuracy metric to measure performance of our models\n",
        "\n",
        "Note: Accuracy Metric requires the data to be balanced otherwise it leads to bias scores"
      ],
      "metadata": {
        "id": "fjhd600KhxPj"
      },
      "id": "fjhd600KhxPj"
    },
    {
      "cell_type": "code",
      "source": [
        "np.round((Xy_train['season'].value_counts().values / Xy_train.shape[0]) * 100, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNiqSXSrjenb",
        "outputId": "3dc28958-2ba8-4829-fa9a-ea20c71bf524"
      },
      "id": "rNiqSXSrjenb",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49.37, 37.56,  8.65,  4.42])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To handle unbalanced data when modelling we can:\n",
        "\n",
        "* use upsampling/downsmapling technique \n",
        "* assign weights to the respective classes\n",
        "* build separate models and/or model within model\n",
        "in addition to the above methods when appropriate"
      ],
      "metadata": {
        "id": "5s8DpzepjidQ"
      },
      "id": "5s8DpzepjidQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight"
      ],
      "metadata": {
        "id": "sqVOE2kyl_37"
      },
      "id": "sqVOE2kyl_37",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_weights = class_weight.compute_sample_weight(\n",
        "        class_weight='balanced',\n",
        "        y = Xy_train['season']\n",
        "        )"
      ],
      "metadata": {
        "id": "4yZ6ykK0mAe2"
      },
      "id": "4yZ6ykK0mAe2",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(classes_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81JgZsNYmAh7",
        "outputId": "91d1e42e-5018-4f65-8080-f9ebf49492e5"
      },
      "id": "81JgZsNYmAh7",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.50641416, 0.6656656 , 2.88943608, 5.65011329])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VdRTEpnNp5uj"
      },
      "id": "VdRTEpnNp5uj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will demonstrate now how to use XGBoost and  CatBoost algorithm for training and building our model"
      ],
      "metadata": {
        "id": "lnqT6apfgqyP"
      },
      "id": "lnqT6apfgqyP"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdgKsx6chG0m",
        "outputId": "07ac0eeb-6986-4048-ff5c-53649b580010"
      },
      "id": "JdgKsx6chG0m",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost.sklearn import XGBClassifier"
      ],
      "metadata": {
        "id": "-j7yciQPhLAb"
      },
      "id": "-j7yciQPhLAb",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline XGBoost Model"
      ],
      "metadata": {
        "id": "NH0KzSczhtl4"
      },
      "id": "NH0KzSczhtl4"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "e18f3117-abf8-4d00-82c6-4c64ee799f0f",
      "metadata": {
        "id": "e18f3117-abf8-4d00-82c6-4c64ee799f0f"
      },
      "outputs": [],
      "source": [
        "model_xgb = XGBClassifier(random_state = seed)\n",
        "XGB = model_xgb.fit(X_train, y_train, sample_weight = classes_weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict = XGB.predict(X_test)"
      ],
      "metadata": {
        "id": "J_6qTIaEhWy-"
      },
      "id": "J_6qTIaEhWy-",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean ROC AUC: %.3f' % accuracy_score(y_test, model_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_DvxhCWhZgH",
        "outputId": "7d2f2aa9-312c-4246-8536-24b0f2240a0a"
      },
      "id": "Y_DvxhCWhZgH",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning XGBoost Hyperparameters"
      ],
      "metadata": {
        "id": "fOoHFhyu-GuG"
      },
      "id": "fOoHFhyu-GuG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will start tuning our XGB classifier model\n",
        "\n",
        "Note: We can also use XGBoost inbuilt early stopping callback function to automatically stop searching over the grid parameters when chosen loss stops decreasing with respective to increase in number of trees.\n",
        "Optuna is another library useful for the same and gives better results in more efficient way."
      ],
      "metadata": {
        "id": "z9O-FyTUrwdA"
      },
      "id": "z9O-FyTUrwdA"
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation procedure\n",
        "fold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)"
      ],
      "metadata": {
        "id": "MrgY_wtkpOOs"
      },
      "id": "MrgY_wtkpOOs",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning Number of Trees/Estimators"
      ],
      "metadata": {
        "id": "_j_gDFYCt0MQ"
      },
      "id": "_j_gDFYCt0MQ"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate = 0.01, eval_metric = 'auc', \n",
        "                      sample_weight = classes_weights, seed = seed)\n",
        "\n",
        "param_grid = {'n_estimators': [15,50,100,150]}\n",
        "\n",
        "GR = GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                  scoring = 'accuracy', cv = fold, n_jobs = -1)    \n",
        "\n",
        "GR_XGB = GR.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best acc score:: %f using %s \"%(GR_XGB.best_score_, GR_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6bBtqxFq3MZ",
        "outputId": "a2e44c9b-75e7-4460-c762-cd5356d858a6"
      },
      "id": "O6bBtqxFq3MZ",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc score:: 0.512148 using {'n_estimators': 150} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We can increase the number of trees to see if it would further help in any significant  increasing of our score.\n",
        "We can then lower learning rate and then again tune number of trees if required thus tuning both of them side by side as they are both closely related"
      ],
      "metadata": {
        "id": "jR1MEsLm8tkE"
      },
      "id": "jR1MEsLm8tkE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning 'max depth' and 'min child weight'\n",
        "\n",
        "* 'max depth' - Increasing this value will make the model more complex and more likely to overfit\n",
        "\n",
        "* 'min child weight' - Minimum sum of instance weight (hessian) needed in a child. The larger min_child_weight is, the more conservative the algorithm will be."
      ],
      "metadata": {
        "id": "eYKf9qi5t5tJ"
      },
      "id": "eYKf9qi5t5tJ"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate = 0.01, n_estimators = 150,\n",
        "                      sample_weight = classes_weights, \n",
        "                      eval_metric = 'auc', seed = 7)\n",
        "\n",
        "param_grid = {'max_depth':range(3,10,2),  \n",
        "              'min_child_weight':range(1,6,2) }\n",
        "\n",
        "GR = GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                  scoring = 'accuracy', cv = fold, n_jobs = -1)    \n",
        "\n",
        "GR_XGB = GR.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best acc score:: %f using %s \"%(GR_XGB.best_score_,GR_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2wp0Bfyq3Oz",
        "outputId": "fa7a2f66-6f1f-4375-a57d-ba5984239e5c"
      },
      "id": "g2wp0Bfyq3Oz",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc score:: 0.516793 using {'max_depth': 5, 'min_child_weight': 1} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning parameter 'gamma'\n",
        "\n",
        "* Gamma - Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be"
      ],
      "metadata": {
        "id": "smI_46wquy9I"
      },
      "id": "smI_46wquy9I"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate = 0.01, n_estimators = 150, max_depth = 5,\n",
        "                      sample_weight = classes_weights, min_child_weight = 1, \n",
        "                      eval_metric = 'auc', seed = 7)\n",
        "\n",
        "param_grid = { 'gamma':[i/10.0 for i in range(0,5)]}\n",
        "\n",
        "GR = GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                  scoring = 'accuracy', cv = fold, n_jobs = -1)    \n",
        "\n",
        "GR_XGB = GR.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best acc score:: %f using %s \"%(GR_XGB.best_score_,GR_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijFQH7Lzu_JF",
        "outputId": "5c85b608-77c1-44ec-cb23-40f22092dc0c"
      },
      "id": "ijFQH7Lzu_JF",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc score:: 0.516793 using {'gamma': 0.0} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning parameters 'subsample' and colsample_bytree\n",
        "\n",
        "* Subsample - Ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting\n",
        "\n",
        "* colsample_bytree - It is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed."
      ],
      "metadata": {
        "id": "Lt70KO7AvB5i"
      },
      "id": "Lt70KO7AvB5i"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate = 0.01, n_estimators = 150, max_depth = 5,  \n",
        "                      gamma = 0, min_child_weight = 1, eval_metric = 'auc', \n",
        "                      sample_weight = classes_weights, seed = 7)\n",
        "\n",
        "param_grid = {'subsample':[i/10.0 for i in range(6,10)],\n",
        "              'colsample_bytree':[i/10.0 for i in range(6,10)]}\n",
        "\n",
        "GR = GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                  scoring = 'accuracy', cv = fold, n_jobs = -1)    \n",
        "\n",
        "GR_XGB = GR.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best acc score:: %f using %s \"%(GR_XGB.best_score_, GR_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqhpemQNvIZq",
        "outputId": "741821ef-3c1f-4c94-9238-be8432091630"
      },
      "id": "gqhpemQNvIZq",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc score:: 0.518631 using {'colsample_bytree': 0.9, 'subsample': 0.9} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning parameter 'alpha'\n",
        "\n",
        "* alpha - L1 regularization term on weights. Increasing this value will make model more conservative."
      ],
      "metadata": {
        "id": "qbm4pcqcvLmS"
      },
      "id": "qbm4pcqcvLmS"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate = 0.01, n_estimators = 150, max_depth = 5,  \n",
        "                      gamma = 0, min_child_weight = 1, eval_metric = 'auc',\n",
        "                      colsample_bytree = 0.9, subsample = 0.9, \n",
        "                      sample_weight = classes_weights, refit = True,\n",
        "                      seed = 7)\n",
        "\n",
        "param_grid = { 'alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n",
        "\n",
        "GR = GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                  scoring = 'accuracy', cv = fold, n_jobs = -1)    \n",
        "\n",
        "GR_XGB = GR.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best acc score:: %f using %s \"%(GR_XGB.best_score_, GR_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2Q1wt-KvVrn",
        "outputId": "be728994-0a95-4dd7-bb3e-63fc1e929849"
      },
      "id": "P2Q1wt-KvVrn",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc score:: 0.518631 using {'alpha': 1e-05} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating XGBoost"
      ],
      "metadata": {
        "id": "NUMTVOv9_q82"
      },
      "id": "NUMTVOv9_q82"
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict = GR_XGB.predict(X_test)"
      ],
      "metadata": {
        "id": "Yhk7-AS8_gOx"
      },
      "id": "Yhk7-AS8_gOx",
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean ROC AUC: %.5f' % accuracy_score(y_test, model_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3llCaGQJ_yqB",
        "outputId": "20c08a79-0eee-4dc2-8ad9-0d619a510e5d"
      },
      "id": "3llCaGQJ_yqB",
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.51072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline CatBoost Model"
      ],
      "metadata": {
        "id": "vjR01GRPvX_D"
      },
      "id": "vjR01GRPvX_D"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTV_lllnvYW2",
        "outputId": "63285f37-1aa7-4ae7-e22f-b783931a498f"
      },
      "id": "eTV_lllnvYW2",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.5-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "k4DlHQkf-Ue_"
      },
      "id": "k4DlHQkf-Ue_",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cat = CatBoostClassifier(eval_metric = 'AUC', auto_class_weights = 'Balanced', \n",
        "                               random_state = seed)\n",
        "cat = model_cat.fit(X_train, y_train, verbose = False)"
      ],
      "metadata": {
        "id": "uWEdhgRIhQmL"
      },
      "id": "uWEdhgRIhQmL",
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict = cat.predict(X_test)"
      ],
      "metadata": {
        "id": "1tObBIxu_T3Z"
      },
      "id": "1tObBIxu_T3Z",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean ROC AUC: %.5f' % accuracy_score(y_test, model_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0H-Xfgw-vN2",
        "outputId": "2f910f31-01ef-4eb0-c046-da5598dcce92"
      },
      "id": "U0H-Xfgw-vN2",
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.52000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice catboost model without tuning also performs slightly better than XGBoost. The reason for this might be that most of our explanatory variables are categorical in nature"
      ],
      "metadata": {
        "id": "K8KXab5WGGXP"
      },
      "id": "K8KXab5WGGXP"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Predict_Season_Modelling (Multi Label).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}